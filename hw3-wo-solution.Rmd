---
title: 'CSCI E-63C: Week 3 Problem Set'
output:
  html_document:
    toc: yes
---

```{r setup, include=FALSE, results='hide'}
library(ggplot2)
library(ISLR)
knitr::opts_chunk$set(echo = TRUE)
```

# Preface

The goal of this week problem set is to practice basic tools available in R for developing linear regression models with one or more variables, to conduct visual and quantitative evaluation of their relative performance and to reason about associated trade-offs.  

We will continue working with the fund-raising dataset (which you have already downloaded and used for the previous problem set).  This time we will use some of the variables available there to develop a model of donors' contributions to the campaign of interest (attribute `contrib` in the `fund-raising.csv` file).  Given the complexity of the problem (it wouldn't be used for competition even twenty years ago otherwise) and limited number of attributes provided in this dataset, we should expect substantial fraction of variability in donors' contributions to remain unexplained as part of this exercise.  Furthermore, given strong correlations between some of the predictors in this dataset it is possible that only a subset of those could be justifiably used in the model (for the reasons related to collinearity - see Ch.3.3.3 section 6 of ISLR).

```{r readData, echo=FALSE, results='hide',fig.width=12,fig.height=12}
frcDat <- read.table("fund-raising.csv",sep=",",header=TRUE, as.is = FALSE)
dim(frcDat)
pairs(frcDat)
```

Below, we will use the model of average donor contribution (attribute `avecontr`) and the total number of contributions by that donor (`ncontrib`) to illustrate tools available in R that will be needed for this problem set.  This is a good moment to pause and reflect on whether we have any expectations as to what the relationship between those two attributes could be.  Would we expect that those who give often also tend to make larger contributions on average?  Or, vice versa?  Or, we do not expect any well defined relationship between them? (You do not need to answer these questions as part of the problem set -- these are here only to stimulate your curiosity as you go through this preface.  The answers are shown immediately below anyway.)

We start with a simple linear model that can be fit using function `lm()` and summarized using `summary`:

```{r nAveContrib}
summary(lm(avecontr~ncontrib,frcDat))
```

Highly significant negative relationship between number of donations and average contribution.  On average, those who give frequently, tend to give less per donation.  Not a shocker, perhaps...

Let's overlay our model predictions on the actually observed data.  The plot of predictor and response with regression line added to it can be generated using standard R functions `plot` and `abline`.  Take a look at help page for `abline()`, this function is just a convenience tool for adding different types of straight lines to the plot, depending on the parameters. In our case, it is very useful that `abline()` knows how to deal with a fitted linear model object returned by `lm()`: it will extract the fitted intercept and slope and draw the corresponding line $y=ax+b$.  Vertical and horizontal dashes indicating $x=0$ and $y=0$ axes are also added using `abline` as shown below:

```{r nAvePlot}
plot(frcDat[,c("ncontrib","avecontr")])
abline(lm(avecontr~ncontrib,frcDat),col=2,lwd=2)
abline(h=0,lty=2)
abline(v=0,lty=2)
```

Overall, not a terribly appealing plot with observations rather unevenly distributed along the model fit.  Additionally, for the highest numbers of contributions our model predicts negative average contribution that hardly makes sense for this problem.  Let's inspect this model's diagnostic plots.

Diagnostic plots for this model can be obtained also by the call to `plot` with the result of `lm()` used as input:

```{r nAveContrDiag,fig.width=8,fig.height=8}
old.par <- par(mfrow=c(2,2))
plot(lm(avecontr~ncontrib,frcDat))
par(old.par)
```

Also problematic...  Funnel-shaped plots of residuals vs. fitted suggest that the data may benefit from a transformation, quantile-quantile plot shows standardized residuals that are way outside of the range of theoretical quantiles (in other words, many of those residuals are way too large for the dataset size), and some of the points are close enough to Cook's distance of 0.5-1 for those contours to show up in residuals vs. leverage plot that is suggestive of problems with the model fit as well.

Let's see if fitting linear model to log-transformed (log base 10 for the ease of going from dollars to their log-transformed values in our heads) values of the number and average amount of the contribution is going to look any better:

```{r nAveContribLog}
summary(lm(log10(avecontr)~log10(ncontrib),frcDat))
```

Numerical values of the model coefficients are now obviously different, but the relationship remains the same -- those who give often, tend to give less on average per donation.

```{r nAvePlotLog}
plot(log10(frcDat[,c("ncontrib","avecontr")]))
abline(lm(log10(avecontr)~log10(ncontrib),frcDat),col=2,lwd=2)
```

Observations are now more evenly distributed around the fit.

```{r nAveContrLogDiag,fig.width=8,fig.height=8}
old.par <- par(mfrow=c(2,2))
plot(lm(log10(avecontr)~log10(ncontrib),frcDat))
par(old.par)
```

Aside from inevitably discrete fitted values for the lower end of the number of contributions (1, 2, 3, ...) the plots of residuals are now upon log-transformation much more like "shapeless clouds", standardized residuals are more on par with theoretical quantiles and no more contours representing Cook's distance of 0.5 and 1 (notice about an order of magnitude decrease in leverage values also).  Overall, far less troubling appearance of diagnostic plots.

We'll use this model for log-transformed data to get confidence and prediction intervals.  R functions `confint` returns confidence intervals for model parameters, while `predict` (with appropriate parameters) returns model predictions for the new data and (if asked), can also return corresponding estimates of uncertainty associated with them:

```{r nAveContrIntls}
confint(lm(log10(avecontr)~log10(ncontrib),frcDat))
10^predict(lm(log10(avecontr)~log10(ncontrib),frcDat),newdata=data.frame(ncontrib=c(9,10,11)),interval='confidence')
10^predict(lm(log10(avecontr)~log10(ncontrib),frcDat),newdata=data.frame(ncontrib=c(9,10,11)),interval='prediction')
```

Note the transformation of the confidence and prediction intervals on the model predictions to put it back onto the original scale of measurements (dollars).

# Problem 1: model of target contribution and last contribution (points: 30/30 â€“ graduate/undergraduate)

Here we will identify the variable most correlated with the outcome (the donations to the campaign of interest - column `contrib` in `fund-raising.csv` file), build simple linear model for this outcome as a function of this variable, evaluate model summary and diagnostic plots and assess impact of using log-transformed (instead of untransformed) attributes on the model peformance.  The following steps provide approximate outline of tasks for achieving these goals:

1. Calculate correlations between all *continuous* attributes in this dataset.  Given potential non-linear relationship between some of the attributes and outcome, it might be prudent to use both Pearson and Spearman correlations to determine which variable is most robustly correlated with the target contributions (`contrib`). [see documentation for the function `cor()`]

```{r P1.1}
# Select continuous variables
continuous_vars <- frcDat[, sapply(frcDat, is.numeric)]

# Calculate Pearson and Spearman correlations with 'contrib'
pearson_corr <- cor(continuous_vars, method = "pearson", use = "complete.obs")
spearman_corr <- cor(continuous_vars, method = "spearman", use = "complete.obs")

# View correlations
print("Pearson Correlations:")
print(pearson_corr)

print("Spearman Correlations:")
print(spearman_corr)
```

2. Fit linear model for target campaign contribution as the outcome and the last contribution by this donor (`lastcontr` in `fund-raising.csv`) as the predictor, using R function `lm`; inspect the fitted model using `summary` function, and use the output to answer the following questions:

```{r p1.2}
# Fit a linear model with 'contrib' as outcome and 'lastcontr' as predictor
model <- lm(contrib ~ lastcontr, data = frcDat)

# Get the summary of the model
summary(model)
```

   + Does this predictor explain significant amount of variability in response?  I.e. is there statistically (!) significant association between them?
   
   + What is the RSE and $R^2$ of this model?  Remember, you can find them in the `summary` output or use `sigma` and `r.sq` slots in the result returned by `summary` instead (the `summary()` command does return a *list*; if instead of just printing the result into the console you save it into a variable, as in `model.summary <- summary(...)`, then you can verify that the content of that variable *is* a list, you can see with `names(model.summary)` which elements this list contains, and you can extract, examine, and use them at will programmatically if you ever need to)
   
   + What are the model coefficients and what would be their interpretation? What is the meaning of the intercept of the model, for example?  What about the slope - how would you interpret its value?

**answers:**

 i) Yes, the P-value is extremely small at 2e-16 and F-statistic very large at 4364, indicating significance.
 
 ii) Residual Standard Error (RSE): 7.692, represents the average amount by which the actual contributions deviate from the predicted contributions by the model.

$R^2$: 0.5572, indicates that approximately 55.72% of the variance in contributions is explained by the last contribution, suggesting a moderate fit of the model.

 iii) Intercept: of 3.523 represents the predicted contribution when the last contribution is 0. So, if a donor's last contribution was zero, their predicted contribution in this model is about 3.523.
 
 Slope: is the coefficient for lastcontr, 0.79523 indicates that for every unit increase in the last contribution, the predicted contribution increases by 0.79523 units. A positive relationship here means that larger previous contributions are associated with larger future contributions.


3. Create scatterplot of target campaign contribution and the last contribution (the attributes used in the model above) and add to the plot the regression line from the model using `abline` function

```{r p1.3}
plot(frcDat[,c("lastcontr","contrib")],main = "Scatterplot of Contributions vs. Last Contribution")
abline(model,col=,lwd=2)
abline(h=0,lty=2)
abline(v=0,lty=2)
```

4. Create diagnostic plots of the model and comment on any irregularities that they present.  For instance, does the plot of residuals vs. fitted values suggest presence of non-linearity that remains unexplained by the model?  Does scale-location plot suggest non-uniformity of variance along the range of fitted values?  Are some standardized residuals far greater than theoretical quantiles?  What about residuals vs. leverage plot and Cook's distance contours therein?  How does your conclusions compare to what's shown in the plot of the predictor and outcome with regression line added to it -- i.e. the plot that was generated above?

```{r p1.4, fig.width=8,fig.height=8}
par(mfrow = c(2, 2))  # Arrange the plots in a 2x2 grid
plot(model)
```
**answers:**

In the residuals vs fitted plot, we see a curved pattern, which may suggest some non-linearity in the data that is not well captured by the model. There are also clear outliers. The QQ plot shows clear deviation from the 45 degree line, especially in the tails, which suggests non-normality. In the scale-location plot, there is a clear fan-like shape visible, which indicates heteroscedasticity. The residuals vs leverage plot show some points (e.g. 1242) that have high leverage and fall outside the Cookâ€™s distance contours. These points could have an undue influence on the regression model and may need further investigation or removal.

These diagnostic plots suggest that the linear model may not fully capture the relationships in the data. There are violations of  linearity, normality of residuals, and constant variance. This might explain discrepancies between the model's performance and the scatterplot with the regression line (from above), where non-linear patterns could be visually apparent. 

5. Use function `confint` to obtain 95% confidence intervals on model parameters.

```{r p1.5}
confint(model)
```

6. Use this model and `predict` function to make predictions for the last contribution values of 10, 20 and 40. Remember that when you pass new data to `predict`, you have to make sure that the variable (column) names in those data match the predictor variable name(s) used in the model, otherwise `predict` will not know how to match the data to the model variables! Use `confidence` and `prediction` settings for parameter `interval` in the call to `predict` to obtain 90% confidence and prediction intervals on these model predictions (please double check what the default confidence level used by those functions is, and adjust if/as necessary).  Explain the differences between interpretation of:
    + confidence intervals on model parameters and model predictions
    + confidence and prediction intervals on model predictions
    + comment on whether confidence or prediction intervals (on predictions) are wider and why
    
```{r p1.6}
new_data <- data.frame(lastcontr = c(10, 20, 40))

# Obtain 90% confidence intervals for the predictions
predictions_conf <- predict(model, newdata = new_data, interval = "confidence", level = 0.90)

# Obtain 90% prediction intervals for the predictions
predictions_pred <- predict(model, newdata = new_data, interval = "prediction", level = 0.90)

# Display the predictions with confidence and prediction intervals
print("90% Confidence Intervals:")
print(predictions_conf)

print("90% Prediction Intervals:")
print(predictions_pred)
```
**answers:**

i) The 95% confidence interval for the slope (lastcontr) is (0.7716, 0.8183), meaning we are 95% confident that the true effect of last contribution on campaign contribution lies within this range. Model predictions are directly shown and the parameters are not outputted (at 90% confidence above), and thus no direct comparison is made here, though we could go through the process to do it if needed.

ii and iii) Confidence intervals are much narrower than prediction intervals, for example for lastcontr = 10, 90% confidence interval (11.24, 11.71) is much narrower than the  prediction interval of (-1.18, 24.13). This is because confidence intervals estimate the average expected contribution for a given value of lastcontr, but prediction intervals account for the variability of individual future observations. Prediction intervals not only includes the uncertainty in estimating the mean (and only mean) contribution but also accounts for the natural variability in contributions. Therefore, prediction intervals are always wider than confidence intervals.

# Problem 2: model using log-transformed attributes (points: 20/30 â€“ graduate/undergraduate)

1. Use `lm()` to fit a regression model of *log-transformed* outcome (`contrib`) as a linear function of *log-transformed* last contribution and use `summary` to evaluate its results.

For the purposes of this exercise we can exclude small number of observations where `lastcontr==0`, otherwise log-transformation will result in negative infinity values for those and error from the call to `lm`. (And what does last contribution of zero represent in the first place, anyway?!  Rounded values of contributions below 1?  That's a rhetorical question aimed at data producers, no need to answer it as part of this problem set.)  When you exclude those observations with `lastcontr==0` please note in your solution how many exactly you have excluded.

```{r p2.1}

# Exclude observations where 'lastcontr' is 0
data_filtered <- subset(frcDat, lastcontr > 0)

# Count and display the number of excluded observations
num_excluded <- nrow(frcDat) - nrow(data_filtered)
cat("Number of excluded observations where lastcontr == 0:", num_excluded, "\n")

# Log-transform the 'contrib' and 'lastcontr' variables
data_filtered$log_contrib <- log(data_filtered$contrib)
data_filtered$log_lastcontr <- log(data_filtered$lastcontr)

# Fit a linear model using log-transformed variables
log_model <- lm(log_contrib ~ log_lastcontr, data = data_filtered)

# Display the summary of the model
summary(log_model)
```

Now that we are done with that - can we compare the fits obtained using untransformed (above) and log-transformed attributes?  Can we directly compare RSE from these two models?  What about comparing $R^2$?  What would we conclude from this? (Please consult ISLR Ch.3.1.3 if unsure)  What would be the physical meaning of model coefficients this time?  What does model intercept represent in this case, for example?  How sensible is this and how does this compare to the meaning of the same parameter (intercept) obtained when fitting on untransformed data?

**answers:**

The RSE for the original model was 7.692 and for the log transformed 0.3996. However, the values cannot be directly compared as the latter value is on a log scale. We can only say a lower RSE in the log-transformed model suggests a better fit on the log scale.

The $R^2$ can be compared and the original of 0.5572 is lower vs the log transformed of 0.5958. This indicates that the log-transformed model explains slightly more variance, which might suggest that the log transformation improves the model's fit.

Slope (0.82016): The slope of 0.82016 means that for every 1% increase in the last contribution, we expect the contribution to increase by about 0.82%. This is because the relationship between log-transformed variables can be interpreted as an elasticity â€” a percentage change in one variable results in a percentage change in the other.

Intercept (0.4612): In the log-transformed model, the intercept represents the expected log of contributions when the log of the last contribution is zero. This can be interpreted as the expected value of log-transformed contributions when lastcontr = 1 (since log(1)=0). If we exponentiate the intercept, we get e^0.4612â‰ˆ1.586, which is the expected contribution when lastcontr = 1.

The log-transformed model is often preferred when the data exhibits non-linearity or heteroscedasticity (as seen in the diagnostic plots of the untransformed model). The log transformation can stabilize variance and linearize relationships, making the model better suited to capturing the underlying patterns in the data. We also got a slightly better $R^2$ after transformation. The coefficients in the log-transformed model have a clear interpretation in terms of percentage changes, which can be more intuitive when dealing with financial or proportional data.

2. Create an XY-scatterplot of log-transformed predictor and response and add corresponding regression line to it.  Compare it to the plot in untransformed coordinates obtained in Problem 1.  What would you conclude from such comparison?

```{r p2.2}
plot(data_filtered[,c("log_lastcontr","log_contrib")],main = "Log-Transformed Contributions vs. Last Contribution")
abline(log_model,col="red",lwd=2)
abline(h=0,lty=2)
abline(v=0,lty=2)
```

**answer:**

The log transformation has effectively linearized the relationship between contributions and last contributions, making the relationship more consistent and easier to model with a linear regression. The original plot showed a notable pattern where contributions seemed to increase with last contributions, but the variance increased as well, indicating that the model struggled to capture the relationship for larger values. The log-transformed plot shows less variability in residuals across the range of values compared to the untransformed plot, where heteroscedasticity was present. Overall, the log transformation has improved the model's fit and interpretability by addressing the issues observed in the untransformed scatterplot.

3. Make diagnostic plots for the model fit on log-transformed outcome and the last contribution.  Compare them to the diagnostic plots generated in Problem 1 for the model fitted using original scale of measurements (untransformed). What can you conclude from this comparison about the relative quality of these two models?

```{r p2.3, fig.width=8,fig.height=8}
par(mfrow = c(2, 2))  # Arrange the plots in a 2x2 grid
plot(log_model)
```
**answers:**

The residuals vs. fitted plot for the log-transformed model looks more homogeneous, with a tighter spread of residuals. The residuals seem to be more evenly distributed around zero, suggesting that the log transformation has helped mitigate some of the non-linearity and heteroscedasticity. However, there are still some outliers.

The Q-Q plot for the log-transformed model still shows some deviations from the theoretical quantiles, particularly in the upper and lower tails, but the deviations are less severe compared to the untransformed model. Improved but problems still persist.

In the log-transformed model's scale-location plot, the spread of residuals is more uniform, and the fan-shaped pattern has been reduced. This indicates that the log transformation has helped stabilize the variance, although some heteroscedasticity still clearly remains.

The residuals vs. leverage plot for the log-transformed model shows fewer extreme points with high leverage. However, there are still some influential points, such as 1664.

The log-transformed model is a better fit overall, addressing many of the key issues present in the untransformed model, such as heteroscedasticity and non-linearity, while providing a more interpretable and reliable relationship between the variables. However the original problems still persist and are not completely resolved.

# Problem 3: Adding second variable to the model (points: 10/10(extra) â€“ graduate/undergraduate)

To explore effects of adding another variable to the model, continue using log-transformed attributes and fit a model of log-transformed outcome (the same target campaign contribution, column `contrib` in `fund-raising.csv`) as a function of the last contribution and average contribution (both log-transformed).  Just an additive model -- no interaction term is necessary at this point. Please obtain and evaluate the summary of this model fit, confidence intervals on its parameters and its diagnostic plots. Where applicable, compare them to the model obtained above and reflect on pros and cons of including average contribution as another variable into the model.  You may find the discussion of *variance inflation factor* (VIF) in ISLR Ch.3.3.3 (Section 6) and its implementation `vif` in `car` library particularly useful in this context. 

```{r p3, fig.width=8,fig.height=8}
library(car)

data_filtered <- subset(frcDat, lastcontr > 0 & avecontr > 0)

# Log-transform the new variable
data_filtered$log_contrib <- log(data_filtered$contrib)
data_filtered$log_lastcontr <- log(data_filtered$lastcontr)
data_filtered$log_avecontr <- log(data_filtered$avecontr)

# Fit the linear model with both log_lastcontr and log_avecontr as predictors
log_model_extended <- lm(log_contrib ~ log_lastcontr + log_avecontr, data = data_filtered)

# Summary of the model
summary(log_model_extended)

# Calculate Variance Inflation Factor (VIF) to assess multicollinearity
vif <- vif(log_model_extended)
print(vif)

# Confidence intervals for the model parameters
confint(log_model_extended)

# Diagnostic plots for the model
par(mfrow = c(2, 2))  # Arrange the plots in a 2x2 grid
plot(log_model_extended)
```

**comments and answers:**

Both predictors, log_lastcontr (0.49406) and log_avecontr (0.46622), have significant p-values (< 2e-16).

The R^2 value is 0.6398, an improvement from the prior 0.5958 where only log_lastcontr was used.

The RSE is now 0.3773, slightly lower than the previous model with one predictor (0.3996), indicating smaller residuals and better model fit.

VIFs: The VIF for log_lastcontr and log_avecontr are both 3.141. These values are below 5, suggesting that multicollinearity is not serious. However, the predictors are somewhat correlated, which is expected given that past contributions and average contributions are likely related. 

Confidence intervals at 95% for each of the predictors look healthy, but are not directly comparable to the models prior (not calculated for the 1 predictor log model), not much to say here.

The diagnostic plots overall show slight to some improvement, especially in terms of reducing heteroscedasticity (more uniform residual spread in the scale-location plot).

Overall, The VIF values show that multicollinearity is not a major issue, so including both predictors does not degrade the model's reliability. Adding log_avecontr to the model improves its overall fit and reduces some of the issues seen in the one-predictor model, however, there are still issues with influential points and thus further investigation can be done.